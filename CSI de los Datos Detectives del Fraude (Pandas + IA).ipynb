{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3604d2df",
      "metadata": {
        "id": "3604d2df"
      },
      "source": [
        "# üïµÔ∏è CSI de los Datos: Detectives del Fraude (Pandas + IA)\n",
        "**Bootcamp:** IA Innovador ‚Äî Laboratorio guiado (3‚ÄØh)  \n",
        "**By:** Ing. Engler Gonz√°lez\n",
        "\n",
        "**Objetivo:** Investigar patrones sospechosos en transacciones usando **pandas** y (opcionalmente) **Gemini** para redactar una narrativa ejecutiva.\n",
        "\n",
        "> **Nota:** El lab funciona 100% con *pandas* aunque no configures la IA.  \n",
        "> Para usar IA, crea la variable de entorno `GOOGLE_API_KEY` en Colab: *Entorno de ejecuci√≥n ‚Üí Configurar variables de entorno ‚Üí A√±adir*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed266e63",
      "metadata": {
        "id": "ed266e63"
      },
      "source": [
        "## 0) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9620f46",
      "metadata": {
        "id": "d9620f46"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas numpy matplotlib google-generativeai\n",
        "\n",
        "import os, math, random, json, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "\n",
        "np.random.seed(7); pd.set_option(\"display.max_colwidth\", 120)\n",
        "# Retrieve the API key from Colab secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    # Fallback for environments where userdata is not available\n",
        "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "model = None\n",
        "# (Opcional IA) Configura tu GOOGLE_API_KEY en Entorno de ejecuci√≥n > Variables de entorno\n",
        "if api_key:\n",
        "    genai.configure(api_key=api_key)\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    print(\"‚úÖ Gemini model configured.\")\n",
        "else:\n",
        "    print(\"‚ùå GOOGLE_API_KEY not found. Gemini model not configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e22dd9",
      "metadata": {
        "id": "52e22dd9"
      },
      "source": [
        "## 1) Generar dataset sint√©tico\n",
        "No necesitas archivos. Simularemos **60 d√≠as** de transacciones en m√∫ltiples pa√≠ses y canales. Inyectaremos anomal√≠as a prop√≥sito (madrugada, montos altos, duplicados, valores faltantes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e441aa",
      "metadata": {
        "id": "66e441aa"
      },
      "outputs": [],
      "source": [
        "# Escenario: transacciones de 60 d√≠as. Inyectamos anomal√≠as.\n",
        "n = 6000\n",
        "countries = [\"CO\", \"MX\", \"US\", \"AR\", \"CL\", \"ES\"]\n",
        "channels = [\"web\", \"app\", \"social_ads\", \"affiliate\", \"email\"]\n",
        "\n",
        "# Distribuci√≥n de horas por tramos (m√°s peso en el d√≠a). Normalizamos para que sume 1.\n",
        "hour_weights = [0.02]*6 + [0.04]*6 + [0.06]*6 + [0.02]*6  # 0-5, 6-11, 12-17, 18-23\n",
        "hour_weights = np.array(hour_weights, dtype=float)\n",
        "hour_weights = hour_weights / hour_weights.sum()\n",
        "\n",
        "hours = np.random.choice(range(0,24), size=n, p=hour_weights)\n",
        "base_amount = np.random.lognormal(mean=3.3, sigma=0.5, size=n) * 10  # distribuci√≥n sesgada\n",
        "country = np.random.choice(countries, size=n, p=[0.32,0.20,0.16,0.12,0.12,0.08])\n",
        "channel = np.random.choice(channels, size=n, p=[0.35,0.25,0.15,0.15,0.10])\n",
        "user_id = np.random.randint(1000, 5000, size=n)\n",
        "days = pd.date_range(end=pd.Timestamp.today().normalize(), periods=60)\n",
        "timestamp = np.random.choice(days, size=n) + pd.to_timedelta(hours, unit=\"h\")\n",
        "\n",
        "# Inyectar patrones sospechosos\n",
        "amount = base_amount.copy()\n",
        "mask_night = (hours < 6) | (hours > 22)\n",
        "amount[mask_night] *= np.random.uniform(1.4, 2.1, size=mask_night.sum())  # montos m√°s altos de madrugada\n",
        "\n",
        "mask_remote = np.isin(country, [\"ES\",\"US\"]) & np.isin(channel, [\"affiliate\",\"social_ads\"])\n",
        "amount[mask_remote] *= np.random.uniform(1.2, 1.8, size=mask_remote.sum())\n",
        "\n",
        "# Outliers y duplicados\n",
        "idx_out = np.random.choice(range(n), size=40, replace=False)\n",
        "amount[idx_out] *= np.random.uniform(3, 10, size=40)\n",
        "duplicated_rows = 30\n",
        "dups = np.random.choice(range(n), size=duplicated_rows, replace=False)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"transaction_id\": [f\"T{100000+i}\" for i in range(n)],\n",
        "    \"user_id\": user_id,\n",
        "    \"amount\": amount.round(2),\n",
        "    \"country\": country,\n",
        "    \"channel\": channel,\n",
        "    \"timestamp\": timestamp\n",
        "})\n",
        "df = pd.concat([df, df.iloc[dups]], ignore_index=True)  # a√±adir duplicados\n",
        "\n",
        "# Nulos/errores de formato\n",
        "df.loc[np.random.choice(df.index, 50, replace=False), \"channel\"] = None\n",
        "df.loc[np.random.choice(df.index, 30, replace=False), \"country\"] = \"??\"\n",
        "df.loc[np.random.choice(df.index, 20, replace=False), \"amount\"] = None\n",
        "\n",
        "print(\"‚úÖ Dataset generado:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "448a42ce",
      "metadata": {
        "id": "448a42ce"
      },
      "source": [
        "## 2) Limpieza de datos (GUIADA)\n",
        "**TODOs**  \n",
        "1. Revisar info general, nulos y duplicados.  \n",
        "2. Eliminar duplicados exactos.  \n",
        "3. Asegurar tipos correctos (`timestamp` ‚Üí datetime, `amount` ‚Üí float).  \n",
        "4. Normalizar categor√≠as (reemplazar `\"??\"` por `NaN`, decidir imputaci√≥n/filtrado).  \n",
        "5. Tratar nulos en `amount` y `channel` (documentar la decisi√≥n).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9991db0c",
      "metadata": {
        "id": "9991db0c"
      },
      "outputs": [],
      "source": [
        "# --- Punto de partida y pistas ---\n",
        "df.info()\n",
        "print(\"\\nNulos antes:\", df.isna().sum())\n",
        "df.isna().mean().sort_values(ascending=False).head(10)\n",
        "\n",
        "print(\"\\nDuplicados antes:\", df.duplicated().sum())\n",
        "# PISTA: df = df.drop_duplicates()\n",
        "# PISTA: df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "# PISTA: df[\"amount\"] = pd.to_numeric(df[\"amount\"], errors=\"coerce\")\n",
        "# PISTA: df[\"country\"] = df[\"country\"].replace(\"??\", np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd999324",
      "metadata": {
        "id": "fd999324"
      },
      "source": [
        "## 3) EDA: entender el comportamiento\n",
        "**TODOs**  \n",
        "6. Crear columnas derivadas: `hour`, `day_of_week`.  \n",
        "7. Res√∫menes clave:  \n",
        "   - monto promedio por pa√≠s  \n",
        "   - distribuci√≥n por canal  \n",
        "   - actividad por hora  \n",
        "   - top usuarios por monto total (opcional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6a27eb",
      "metadata": {
        "id": "2f6a27eb"
      },
      "outputs": [],
      "source": [
        "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "df[\"day_of_week\"] = df[\"timestamp\"].dt.day_name()\n",
        "\n",
        "mean_by_country = df.groupby(\"country\", dropna=True)[\"amount\"].mean().sort_values(ascending=False)\n",
        "count_by_channel = df[\"channel\"].value_counts(dropna=False)\n",
        "activity_by_hour = df.groupby(\"hour\")[\"transaction_id\"].count()\n",
        "\n",
        "print(\"Monto promedio por pa√≠s:\"); display(mean_by_country.head(10))\n",
        "print(\"\\nDistribuci√≥n por canal:\"); display(count_by_channel)\n",
        "print(\"\\nActividad por hora:\"); display(activity_by_hour.head(24))\n",
        "\n",
        "# Gr√°fico simple (matplotlib)\n",
        "plt.figure()\n",
        "activity_by_hour.plot(kind=\"bar\")\n",
        "plt.title(\"Transacciones por hora\")\n",
        "plt.xlabel(\"Hora del d√≠a\")\n",
        "plt.ylabel(\"Conteo\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ce6d14e",
      "metadata": {
        "id": "0ce6d14e"
      },
      "source": [
        "## 4) Detecci√≥n de outliers y reglas de sospecha\n",
        "**TODOs**  \n",
        "8. Detectar outliers por IQR en `amount`.  \n",
        "9. Crear reglas heur√≠sticas (ajusta umbrales con tu EDA):  \n",
        "   - madrugada (`hour` < 6 o > 22) con `amount` > p95  \n",
        "   - `affiliate`/`social_ads` con `amount` > p95  \n",
        "   - `country` o `channel` nulos con `amount` > p95  \n",
        "10. Construir un **score de sospecha** sumando reglas (0‚Äì3/4).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7983f8de",
      "metadata": {
        "id": "7983f8de"
      },
      "outputs": [],
      "source": [
        "q1, q3 = df[\"amount\"].quantile([0.25, 0.75])\n",
        "iqr = q3 - q1\n",
        "lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
        "df[\"is_outlier_amount\"] = (df[\"amount\"] < lower) | (df[\"amount\"] > upper)\n",
        "\n",
        "p95 = df[\"amount\"].quantile(0.95)\n",
        "df[\"is_night\"] = (df[\"hour\"] < 6) | (df[\"hour\"] > 22)\n",
        "df[\"rule_night_high\"] = df[\"is_night\"] & (df[\"amount\"] > p95)\n",
        "df[\"rule_affiliate_high\"] = df[\"channel\"].isin([\"affiliate\",\"social_ads\"]) & (df[\"amount\"] > p95)\n",
        "df[\"rule_missing_high\"] = (df[\"country\"].isna() | df[\"channel\"].isna()) & (df[\"amount\"] > p95)\n",
        "\n",
        "rule_cols = [\"is_outlier_amount\",\"rule_night_high\",\"rule_affiliate_high\",\"rule_missing_high\"]\n",
        "df[\"suspicion_score\"] = df[rule_cols].sum(axis=1)\n",
        "\n",
        "df[[\"amount\",\"hour\",\"country\",\"channel\",\"is_outlier_amount\",\"rule_night_high\",\"rule_affiliate_high\",\"rule_missing_high\",\"suspicion_score\"]].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "536501cc",
      "metadata": {
        "id": "536501cc"
      },
      "source": [
        "## 5) Ranking de casos y explicaci√≥n\n",
        "**TODOs**  \n",
        "11. Ordena por `suspicion_score` y revisa el **Top 20**. Escribe 3 observaciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d44e594",
      "metadata": {
        "id": "1d44e594"
      },
      "outputs": [],
      "source": [
        "top_cases = df.sort_values([\"suspicion_score\",\"amount\"], ascending=[False, False]).head(20)\n",
        "top_cases[[\"transaction_id\",\"user_id\",\"amount\",\"country\",\"channel\",\"hour\",\"suspicion_score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69adbabf",
      "metadata": {
        "id": "69adbabf"
      },
      "source": [
        "## 6) (Opcional) IA para narrativa ejecutiva\n",
        "Si tienes `GOOGLE_API_KEY`, genera un *brief* de 6 l√≠neas para directivos con patrones, acciones y m√©tricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80d3458",
      "metadata": {
        "id": "f80d3458"
      },
      "outputs": [],
      "source": [
        "if model:\n",
        "    resumen_stats = {\n",
        "        \"p95_amount\": float(p95),\n",
        "        \"outlier_rate\": float(df[\"is_outlier_amount\"].mean()),\n",
        "        \"night_rate\": float(df[\"is_night\"].mean()),\n",
        "        \"top_channels\": df[\"channel\"].value_counts().head(3).to_dict()\n",
        "    }\n",
        "    prompt = f\"\"\"\n",
        "    Eres analista forense de datos. Con base en:\n",
        "    Stats: {json.dumps(resumen_stats)}\n",
        "    Reglas aplicadas: {rule_cols}\n",
        "    Redacta un briefing ejecutivo (6 l√≠neas) explicando:\n",
        "    - Qu√© patrones sugieren posible fraude\n",
        "    - Acciones inmediatas (reglas de negocio, l√≠mites, monitoreo)\n",
        "    - M√©tricas a vigilar la pr√≥xima semana\n",
        "    \"\"\"\n",
        "    print(model.generate_content(prompt).text)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è IA no configurada. El an√°lisis se puede entregar igual con pandas y gr√°ficos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c71b034",
      "metadata": {
        "id": "5c71b034"
      },
      "source": [
        "## 7) Reto final (entrega)\n",
        "12. Ajusta y compara umbrales (`p90`/`p95`/`p99`).  \n",
        "13. A√±ade m√°s pa√≠ses y **1 regla nueva** por pa√≠s-hora.  \n",
        "14. Genera **2 gr√°ficos** que respalden tus reglas (ej: d√≠a vs noche, por canal).  \n",
        "15. Redacta **5 conclusiones numeradas**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed04b649",
      "metadata": {
        "id": "ed04b649"
      },
      "outputs": [],
      "source": [
        "print(\"üß© Reto final: ajusta umbrales, agrega 1 regla nueva, 2 gr√°ficos y 5 conclusiones.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}